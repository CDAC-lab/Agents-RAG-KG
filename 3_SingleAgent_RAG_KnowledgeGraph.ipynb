{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mHFd_GntqRP"
      },
      "source": [
        "# Single Agent over RAG + Knowledge Graph (Neo4j)\n",
        "\n",
        "You will build a single agent with **two tools**:\n",
        "1) `university_retriever` (RAG)\n",
        "2) `neo4j_qa` (Knowledge Graph Q&A via NL→Cypher)\n",
        "\n",
        "The agent selects the correct tool:\n",
        "- fuzzy text questions → RAG tool\n",
        "- relationship/path questions → KG tool\n",
        "\n",
        "Includes a **tool-selection tracing** cell to show why the agent chose each tool.\n"
      ],
      "id": "1mHFd_GntqRP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrmN-l3xtqRT"
      },
      "source": [
        "## 1) Install dependencies"
      ],
      "id": "LrmN-l3xtqRT"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxqcn2-5tqRU",
        "outputId": "01b7f120-02e0-45bd-deed-86bdd475e358"
      },
      "source": [
        "!pip -q install -U langchain langchain-community langchain-openai langchain-neo4j neo4j faiss-cpu tiktoken"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/102.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.8/102.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.6/84.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m476.0/476.0 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/204.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.2/328.2 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "id": "gxqcn2-5tqRU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLjlphOntqRV"
      },
      "source": [
        "## 2) Configure OpenAI and Neo4j Aura credentials"
      ],
      "id": "RLjlphOntqRV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9gn7gCztqRV"
      },
      "source": [
        "import os, getpass\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key: \")\n",
        "\n",
        "NEO4J_URI = \"neo4j+s://ead18442.databases.neo4j.io\"\n",
        "NEO4J_USER = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"fz1Hzz1Z-Gzh8zYDwlfujRKHhTM9zq4eC5QAYp1YGWY\"\n"
      ],
      "execution_count": 4,
      "outputs": [],
      "id": "n9gn7gCztqRV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhtkXAKjtqRV"
      },
      "source": [
        "## 3) Connect to Neo4j and seed a tiny University KG (optional)\n",
        "If you already have the University graph loaded, you can skip seeding."
      ],
      "id": "xhtkXAKjtqRV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "secR-qtptqRW",
        "outputId": "bbcea8af-adbb-4a25-82f1-b9027c3403ad"
      },
      "source": [
        "from langchain_neo4j import Neo4jGraph\n",
        "\n",
        "graph = Neo4jGraph(url=NEO4J_URI, username=NEO4J_USER, password=NEO4J_PASSWORD)\n",
        "\n",
        "# Optional seed (idempotent). Comment out if you don't want writes.\n",
        "graph.query(\"\"\"\n",
        "MERGE (person:Class {name:\"Person\"})\n",
        "MERGE (student:Class {name:\"Student\"})\n",
        "MERGE (phd:Class {name:\"PhDStudent\"})\n",
        "MERGE (academic:Class {name:\"Academic\"})\n",
        "MERGE (prof:Class {name:\"Professor\"})\n",
        "MERGE (student)-[:SUBCLASS_OF]->(person)\n",
        "MERGE (phd)-[:SUBCLASS_OF]->(student)\n",
        "MERGE (academic)-[:SUBCLASS_OF]->(person)\n",
        "MERGE (prof)-[:SUBCLASS_OF]->(academic)\n",
        "MERGE (alice:Person {id:\"Alice\"})\n",
        "MERGE (bob:Person {id:\"Bob\"})\n",
        "MERGE (g:Group {name:\"EnergyAIGroup\"})\n",
        "MERGE (alice)-[:TYPE]->(phd)\n",
        "MERGE (alice)-[:TYPE]->(student)\n",
        "MERGE (alice)-[:TYPE]->(person)\n",
        "MERGE (bob)-[:TYPE]->(prof)\n",
        "MERGE (bob)-[:TYPE]->(academic)\n",
        "MERGE (bob)-[:TYPE]->(person)\n",
        "MERGE (alice)-[:SUPERVISED_BY]->(bob)\n",
        "MERGE (bob)-[:MEMBER_OF]->(g)\n",
        "MERGE (alice)-[:AFFILIATED_WITH]->(g)\n",
        "\"\"\")\n",
        "\n",
        "graph.refresh_schema()\n",
        "print(graph.schema)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node properties:\n",
            "Person {id: STRING, profile: STRING, embedding: LIST}\n",
            "Class {name: STRING}\n",
            "Group {name: STRING, description: STRING, embedding: LIST}\n",
            "Relationship properties:\n",
            "\n",
            "The relationships:\n",
            "(:Person)-[:TYPE]->(:Class)\n",
            "(:Person)-[:AFFILIATED_WITH]->(:Group)\n",
            "(:Person)-[:SUPERVISED_BY]->(:Person)\n",
            "(:Person)-[:MEMBER_OF]->(:Group)\n",
            "(:Class)-[:SUBCLASS_OF]->(:Class)\n"
          ]
        }
      ],
      "id": "secR-qtptqRW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArIfBFeUtqRW"
      },
      "source": [
        "## 4) Build the RAG retriever tool\n",
        "This tool answers fuzzy text questions like: “What does EnergyAIGroup focus on?”"
      ],
      "id": "ArIfBFeUtqRW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmngxO7htqRW"
      },
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.tools import tool\n",
        "\n",
        "docs = [\n",
        "    Document(page_content=\"Alice is a PhD student researching neuro-symbolic AI, knowledge graphs, and reasoning systems.\",\n",
        "             metadata={\"entity\":\"Alice\",\"type\":\"Person\"}),\n",
        "    Document(page_content=\"Bob is a Professor working on ontology engineering and graph-based AI. He supervises students.\",\n",
        "             metadata={\"entity\":\"Bob\",\"type\":\"Person\"}),\n",
        "    Document(page_content=\"EnergyAIGroup focuses on AI for sustainability, energy forecasting, optimisation, and climate modelling.\",\n",
        "             metadata={\"entity\":\"EnergyAIGroup\",\"type\":\"Group\"}),\n",
        "]\n",
        "\n",
        "emb = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "chunks = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=30).split_documents(docs)\n",
        "vs = FAISS.from_documents(chunks, emb)\n",
        "retriever = vs.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "@tool\n",
        "def university_retriever(query: str) -> str:\n",
        "    \"\"\"Retrieve relevant University text snippets for a query.\"\"\"\n",
        "    hits = retriever.invoke(query)\n",
        "    return \"\\n\\n\".join([f\"[{d.metadata}] {d.page_content}\" for d in hits])\n"
      ],
      "execution_count": 18,
      "outputs": [],
      "id": "kmngxO7htqRW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUnkfkuQtqRX"
      },
      "source": [
        "## 5) Build the KG tool (Natural Language → Cypher)\n",
        "We use GraphCypherQAChain. LangChain requires an explicit safety acknowledgement."
      ],
      "id": "YUnkfkuQtqRX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOl8jfi2tqRX"
      },
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_neo4j import GraphCypherQAChain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "CYPHER_PROMPT = ChatPromptTemplate.from_template(\"\"\"\n",
        "You generate Cypher for Neo4j using the provided schema.\n",
        "Rules:\n",
        "- READ ONLY (MATCH/RETURN). Never write (no CREATE/MERGE/DELETE/SET).\n",
        "- Return scalar properties, NOT full nodes.\n",
        "  Example: RETURN supervisor.id AS supervisor\n",
        "- Prefer `id` or `name` properties when returning people/groups.\n",
        "\n",
        "Schema:\n",
        "{schema}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Cypher:\n",
        "\"\"\")\n",
        "\n",
        "kg_chain = GraphCypherQAChain.from_llm(\n",
        "    llm,\n",
        "    graph=graph,\n",
        "    # cypher_prompt=CYPHER_PROMPT,\n",
        "    verbose=False,\n",
        "    validate_cypher=True,\n",
        "    use_function_response=True,\n",
        "    allow_dangerous_requests=True\n",
        ")\n",
        "\n",
        "@tool\n",
        "def neo4j_qa(question: str) -> str:\n",
        "    \"\"\"Answer relationship/path questions using Neo4j (NL→Cypher).\"\"\"\n",
        "    res = kg_chain.run({\"query\": question})\n",
        "\n",
        "    # Print once while debugging (remove later)\n",
        "    print(\"RAW kg_chain.invoke:\", res)\n",
        "\n",
        "    if isinstance(res, str):\n",
        "        return res\n",
        "\n",
        "    for key in [\"result\", \"output\", \"answer\"]:\n",
        "        if key in res and isinstance(res[key], str) and res[key].strip():\n",
        "            return res[key]\n",
        "\n",
        "    # If we get here, return the whole thing for visibility\n",
        "    return str(res)\n"
      ],
      "execution_count": 51,
      "outputs": [],
      "id": "rOl8jfi2tqRX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu0tO8SEtqRX"
      },
      "source": [
        "## 6) Create a v1 ReAct agent with both tools"
      ],
      "id": "Hu0tO8SEtqRX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs1wyeQYtqRX"
      },
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain.messages import HumanMessage\n",
        "\n",
        "tools = [university_retriever, neo4j_qa]\n",
        "\n",
        "agent = create_agent(\n",
        "    llm,\n",
        "    tools=tools,\n",
        "    system_prompt=(\n",
        "        \"You are a university assistant. Choose the best tool:\\n\"\n",
        "        \"- Use neo4j_qa for relationship/path/type questions \"\n",
        "        \"(supervises, member of, affiliated with, types, paths).\\n\"\n",
        "        \"- Use university_retriever for fuzzy descriptive questions \"\n",
        "        \"(focus area, research interests).\\n\"\n",
        "        \"Always cite evidence from tools. If unsure, ask for clarification.\"\n",
        "    )\n",
        ")"
      ],
      "execution_count": 40,
      "outputs": [],
      "id": "Gs1wyeQYtqRX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ4Yp2rntqRY"
      },
      "source": [
        "## 7) Run a few questions"
      ],
      "id": "mQ4Yp2rntqRY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KquRp2hRtqRY",
        "outputId": "be8dc758-9908-4062-8839-beed53c7aa83"
      },
      "source": [
        "agent.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Who supervises Alice?\")]},\n",
        ")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAW kg_chain.invoke: {'query': 'Who supervises Alice?', 'result': 'Alice is supervised by Bob, a professor working on artificial intelligence, ontology engineering, and graph-based systems.'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Who supervises Alice?', additional_kwargs={}, response_metadata={}, id='f2b42e1d-b41d-4c9c-b1b1-7f7755d23cba'),\n",
              "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_83554c687e', 'id': 'chatcmpl-CnIwnYBFzgVKj0Ya8IoPfl1Tp8XV4', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b25df-2b32-7d43-b7e3-dc79678205bb-0', tool_calls=[{'name': 'neo4j_qa', 'args': {'question': 'Who supervises Alice?'}, 'id': 'call_VXuq0AmDgBaLN1oV0MYY04xH', 'type': 'tool_call'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='Alice is supervised by Bob, a professor working on artificial intelligence, ontology engineering, and graph-based systems.', name='neo4j_qa', id='77b7113d-8116-4750-bbd6-d13076c4fdb0', tool_call_id='call_VXuq0AmDgBaLN1oV0MYY04xH'),\n",
              "  AIMessage(content='Alice is supervised by Bob, who is a professor specializing in artificial intelligence, ontology engineering, and graph-based systems.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 205, 'total_tokens': 229, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e1dc348028', 'id': 'chatcmpl-CnIwsJV4rla3pSLS50pXqRfQJl1sE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b25df-3fd5-7ba0-a505-13a90766346f-0', usage_metadata={'input_tokens': 205, 'output_tokens': 24, 'total_tokens': 229, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "id": "KquRp2hRtqRY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3nucxD9tqRY",
        "outputId": "9d7b5100-ab51-451a-e94d-a38f9fbedf47"
      },
      "source": [
        "agent.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"What does EnergyAIGroup focus on? Use evidence.\")]},\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='What does EnergyAIGroup focus on? Use evidence.', additional_kwargs={}, response_metadata={}, id='7ae0bfbb-23ec-433b-a7ca-f786a3c851fa'),\n",
              "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 158, 'total_tokens': 179, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_11f3029f6b', 'id': 'chatcmpl-CnISRWX9COconZUfEwMiYL3WAHZOm', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b25c2-75f7-7a53-8e5b-42a038da2e6a-0', tool_calls=[{'name': 'university_retriever', 'args': {'query': 'EnergyAIGroup focus area'}, 'id': 'call_bKrSMcjFO9BsVCpr6VR9zea0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 158, 'output_tokens': 21, 'total_tokens': 179, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content=\"[{'entity': 'EnergyAIGroup', 'type': 'Group'}] EnergyAIGroup focuses on AI for sustainability, energy forecasting, optimisation, and climate modelling.\\n\\n[{'entity': 'Alice', 'type': 'Person'}] Alice is a PhD student researching neuro-symbolic AI, knowledge graphs, and reasoning systems.\\n\\n[{'entity': 'Bob', 'type': 'Person'}] Bob is a Professor working on ontology engineering and graph-based AI. He supervises students.\", name='university_retriever', id='b40d0e03-9046-4616-bfe4-43413f7404b6', tool_call_id='call_bKrSMcjFO9BsVCpr6VR9zea0'),\n",
              "  AIMessage(content='The EnergyAIGroup focuses on AI for sustainability, energy forecasting, optimization, and climate modeling.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 289, 'total_tokens': 309, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_11f3029f6b', 'id': 'chatcmpl-CnISVk4Ujm724Q9bzUikuUpn2KBBj', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b25c2-850a-74c0-9945-93a7ead46af4-0', usage_metadata={'input_tokens': 289, 'output_tokens': 20, 'total_tokens': 309, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "id": "C3nucxD9tqRY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCuSk8SetqRY",
        "outputId": "65bfb1f6-e4e2-4017-b9f0-b99bf75c013f"
      },
      "source": [
        "agent.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Which research group is Alice affiliated with?\")]},\n",
        ")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Which research group is Alice affiliated with?', additional_kwargs={}, response_metadata={}, id='44113d4a-81db-4611-bbf7-80f8e4240e52'),\n",
              "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 155, 'total_tokens': 179, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_83554c687e', 'id': 'chatcmpl-CnIVaQmW0eJ8JvotHET0RE63Uvdqn', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b25c5-6f6f-7aa3-91af-374752315e78-0', tool_calls=[{'name': 'neo4j_qa', 'args': {'question': 'Which research group is Alice affiliated with?'}, 'id': 'call_w6M5KMW5K11jUkKwjVD7Dmok', 'type': 'tool_call'}], usage_metadata={'input_tokens': 155, 'output_tokens': 24, 'total_tokens': 179, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='Alice is affiliated with the EnergyAIGroup research group.', name='neo4j_qa', id='570f8a55-da73-469c-be5b-7f2b8e3673c3', tool_call_id='call_w6M5KMW5K11jUkKwjVD7Dmok'),\n",
              "  AIMessage(content='Alice is affiliated with the EnergyAIGroup research group.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 201, 'total_tokens': 213, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e819e3438b', 'id': 'chatcmpl-CnIVfOOXUi0ZxbAb3FPKcJKhGcedF', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b25c5-8305-7521-ac8d-253677dc5c62-0', usage_metadata={'input_tokens': 201, 'output_tokens': 12, 'total_tokens': 213, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "id": "BCuSk8SetqRY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16LnPrlftqRY"
      },
      "source": [
        "## 8) Tool-selection tracing (why did it choose RAG vs KG?)\n",
        "This cell shows the tool calls the agent made, the input sent to each tool, and the output snippet."
      ],
      "id": "16LnPrlftqRY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt8fAliUtqRY"
      },
      "source": [
        "from langchain.messages import AIMessage, ToolMessage\n",
        "\n",
        "def trace_agent(question: str):\n",
        "    print(\"\\n\" + \"=\" * 90)\n",
        "    print(\"QUESTION:\", question)\n",
        "    print(\"=\" * 90)\n",
        "\n",
        "    # Invoke v1 agent (message-based)\n",
        "    res = agent.invoke({\n",
        "        \"messages\": [HumanMessage(content=question)]\n",
        "    })\n",
        "\n",
        "    messages = res.get(\"messages\", [])\n",
        "\n",
        "    print(\"\\nTOOL TRACE:\")\n",
        "\n",
        "    step = 1\n",
        "    for i, msg in enumerate(messages):\n",
        "        # 1) Model deciding to call a tool\n",
        "        if isinstance(msg, AIMessage) and msg.tool_calls:\n",
        "            for call in msg.tool_calls:\n",
        "                print(f\"\\nStep {step}:\")\n",
        "                print(\"  Tool chosen:\", call[\"name\"])\n",
        "                print(\"  Tool input :\", call[\"args\"])\n",
        "                step += 1\n",
        "\n",
        "        # 2) Tool returning evidence\n",
        "        if isinstance(msg, ToolMessage):\n",
        "            print(\"  Tool output snippet:\")\n",
        "            print(\" \", msg.content.replace(\"\\n\", \" \")[:300])\n",
        "\n",
        "    # 3) Final model answer = last AIMessage without tool calls\n",
        "    final_answer = None\n",
        "    for msg in reversed(messages):\n",
        "        if isinstance(msg, AIMessage) and not msg.tool_calls:\n",
        "            final_answer = msg.content\n",
        "            break\n",
        "\n",
        "    print(\"\\nFINAL ANSWER:\")\n",
        "    print(final_answer)"
      ],
      "execution_count": 28,
      "outputs": [],
      "id": "dt8fAliUtqRY"
    },
    {
      "cell_type": "code",
      "source": [
        "for q in [\n",
        "    \"Who supervises Alice?\",\n",
        "    \"What does EnergyAIGroup focus on?\",\n",
        "    \"Which classes is Bob an instance of?\",\n",
        "    \"Who works on neuro-symbolic reasoning?\",\n",
        "]:\n",
        "    trace_agent(q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-fKJBe9xm6s",
        "outputId": "526f537e-c4d3-48f8-8ea6-0083b6a1bca6"
      },
      "id": "z-fKJBe9xm6s",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========================================================================================\n",
            "QUESTION: Who supervises Alice?\n",
            "==========================================================================================\n",
            "\n",
            "TOOL TRACE:\n",
            "\n",
            "Step 1:\n",
            "  Tool chosen: neo4j_qa\n",
            "  Tool input : {'question': 'Who supervises Alice?'}\n",
            "  Tool output snippet:\n",
            "  I don't know the answer.\n",
            "\n",
            "FINAL ANSWER:\n",
            "I couldn't find information on who supervises Alice. If you have more context or details, please provide them, and I'll try to assist you further.\n",
            "\n",
            "==========================================================================================\n",
            "QUESTION: What does EnergyAIGroup focus on?\n",
            "==========================================================================================\n",
            "\n",
            "TOOL TRACE:\n",
            "\n",
            "Step 1:\n",
            "  Tool chosen: university_retriever\n",
            "  Tool input : {'query': 'EnergyAIGroup focus area'}\n",
            "  Tool output snippet:\n",
            "  [{'entity': 'EnergyAIGroup', 'type': 'Group'}] EnergyAIGroup focuses on AI for sustainability, energy forecasting, optimisation, and climate modelling.  [{'entity': 'Alice', 'type': 'Person'}] Alice is a PhD student researching neuro-symbolic AI, knowledge graphs, and reasoning systems.  [{'entity':\n",
            "\n",
            "FINAL ANSWER:\n",
            "The EnergyAIGroup focuses on AI for sustainability, energy forecasting, optimization, and climate modeling.\n",
            "\n",
            "==========================================================================================\n",
            "QUESTION: Which classes is Bob an instance of?\n",
            "==========================================================================================\n",
            "\n",
            "TOOL TRACE:\n",
            "\n",
            "Step 1:\n",
            "  Tool chosen: neo4j_qa\n",
            "  Tool input : {'question': 'Which classes is Bob an instance of?'}\n",
            "  Tool output snippet:\n",
            "  Bob is an instance of Academic, Professor, and Person classes.\n",
            "\n",
            "FINAL ANSWER:\n",
            "Bob is an instance of the classes: Academic, Professor, and Person.\n",
            "\n",
            "==========================================================================================\n",
            "QUESTION: Who works on neuro-symbolic reasoning?\n",
            "==========================================================================================\n",
            "\n",
            "TOOL TRACE:\n",
            "\n",
            "Step 1:\n",
            "  Tool chosen: university_retriever\n",
            "  Tool input : {'query': 'neuro-symbolic reasoning'}\n",
            "  Tool output snippet:\n",
            "  [{'entity': 'Alice', 'type': 'Person'}] Alice is a PhD student researching neuro-symbolic AI, knowledge graphs, and reasoning systems.  [{'entity': 'Bob', 'type': 'Person'}] Bob is a Professor working on ontology engineering and graph-based AI. He supervises students.  [{'entity': 'EnergyAIGroup', '\n",
            "\n",
            "FINAL ANSWER:\n",
            "Alice, a PhD student, is researching neuro-symbolic AI, knowledge graphs, and reasoning systems. Additionally, Bob, a professor, is involved in related areas such as ontology engineering and graph-based AI.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS-fQA3btqRZ"
      },
      "source": [
        "## Reflection\n",
        "- Which questions go to which tool, and why?\n",
        "- What risks exist with NL→Cypher?\n",
        "- Why is this more reliable than a pure RAG system?\n"
      ],
      "id": "kS-fQA3btqRZ"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}