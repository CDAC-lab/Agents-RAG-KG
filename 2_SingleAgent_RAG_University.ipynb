{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ5T_K3iqEkk"
      },
      "source": [
        "# Single Agent with RAG\n",
        "\n",
        "Build:\n",
        "- A small University corpus\n",
        "- A FAISS vector store and a Retriever (called via `.invoke()`)\n",
        "- A Retriever Tool (`@tool`)\n",
        "- A ReAct agent (`create_react_agent`) + `AgentExecutor`\n",
        "\n",
        "Learning outcome: the agent **uses the tool** to ground its answer.\n"
      ],
      "id": "uJ5T_K3iqEkk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRdGVaKFqEkq"
      },
      "source": [
        "## 1) Install dependencies"
      ],
      "id": "zRdGVaKFqEkq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RijxHqOnqEks",
        "outputId": "0416562d-cc5e-4ab8-8cce-ab5eefc72c30"
      },
      "source": [
        "!pip -q install -U langchain langchain-community langchain-openai faiss-cpu tiktoken"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/102.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.8/102.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.6/84.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m476.0/476.0 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "id": "RijxHqOnqEks"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpH8uZX7qEku"
      },
      "source": [
        "## 2) Set API key (OpenAI)\n",
        "We use `getpass` so your key isn't printed in the notebook output."
      ],
      "id": "HpH8uZX7qEku"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrINZ3uFqEkv",
        "outputId": "79d246c7-cde3-4b88-f0e7-8c30070ac314"
      },
      "source": [
        "import os, getpass\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key: \")\n",
        "print(\"Key set:\", \"OPENAI_API_KEY\" in os.environ)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API Key: ··········\n",
            "Key set: True\n"
          ]
        }
      ],
      "id": "GrINZ3uFqEkv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnAlC8ZcqEkw"
      },
      "source": [
        "## 3) Create a small University corpus\n",
        "These are the kinds of snippets you later retrieve in RAG."
      ],
      "id": "ZnAlC8ZcqEkw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLfOIyzuqEkx",
        "outputId": "b8045684-0885-47ab-b416-5b725a144ebf"
      },
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "docs = [\n",
        "    Document(page_content=\"Alice is a PhD student researching neuro-symbolic AI, knowledge graphs, and reasoning systems.\",\n",
        "             metadata={\"entity\":\"Alice\",\"type\":\"Person\"}),\n",
        "    Document(page_content=\"Bob is a Professor working on ontology engineering and graph-based AI. He supervises students.\",\n",
        "             metadata={\"entity\":\"Bob\",\"type\":\"Person\"}),\n",
        "    Document(page_content=\"EnergyAIGroup focuses on AI for sustainability, energy forecasting, optimisation, and climate modelling.\",\n",
        "             metadata={\"entity\":\"EnergyAIGroup\",\"type\":\"Group\"}),\n",
        "    Document(page_content=\"University AI policy: use least-privilege access for LLM tools, prefer read-only database permissions in labs, and validate tool outputs.\",\n",
        "             metadata={\"entity\":\"UniversityPolicy\",\"type\":\"Policy\"}),\n",
        "]\n",
        "len(docs)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "id": "PLfOIyzuqEkx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srdEVZUsqEky"
      },
      "source": [
        "## 4) Build a vector store and a retriever\n",
        "Key idea:\n",
        "- embeddings turn text into vectors\n",
        "- vector store supports similarity search\n",
        "- retriever is the interface we call via `retriever.invoke(query)`"
      ],
      "id": "srdEVZUsqEky"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAfnXA_ZqEkz",
        "outputId": "f90d1613-51d9-4663-996f-46be47bfe3bf"
      },
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Embeddings model (OpenAI)\n",
        "emb = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# Chunk the docs (important once docs get longer)\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=220, chunk_overlap=40)\n",
        "chunks = splitter.split_documents(docs)\n",
        "\n",
        "# Build a local FAISS vector index\n",
        "vs = FAISS.from_documents(chunks, emb)\n",
        "\n",
        "# Create a retriever (LangChain v1 style: call with .invoke())\n",
        "retriever = vs.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "len(chunks)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "id": "WAfnXA_ZqEkz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLuP2gpTqEk0"
      },
      "source": [
        "## 5) Inspect retrieval\n",
        "Before asking the model, always inspect what context is being retrieved."
      ],
      "id": "DLuP2gpTqEk0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqk6Mp_7qEk1",
        "outputId": "4443b873-7f41-4a76-b5d9-42b9f199caf1"
      },
      "source": [
        "q = \"Who works on neuro-symbolic reasoning?\"\n",
        "hits = retriever.invoke(q)  # v1 retriever call\n",
        "\n",
        "for h in hits:\n",
        "    print(\"----\", h.metadata)\n",
        "    print(h.page_content)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- {'entity': 'Alice', 'type': 'Person'}\n",
            "Alice is a PhD student researching neuro-symbolic AI, knowledge graphs, and reasoning systems.\n",
            "---- {'entity': 'Bob', 'type': 'Person'}\n",
            "Bob is a Professor working on ontology engineering and graph-based AI. He supervises students.\n",
            "---- {'entity': 'UniversityPolicy', 'type': 'Policy'}\n",
            "University AI policy: use least-privilege access for LLM tools, prefer read-only database permissions in labs, and validate tool outputs.\n"
          ]
        }
      ],
      "id": "zqk6Mp_7qEk1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9eboZytqEk1"
      },
      "source": [
        "## 6) Wrap retrieval as a Tool\n",
        "Tools are functions the agent can call.\n",
        "We return a short evidence bundle that the agent can cite."
      ],
      "id": "o9eboZytqEk1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xql7G6xqEk2",
        "outputId": "a96cb917-5269-4421-a7dd-fb722d4e6ae1"
      },
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def university_retriever(query: str) -> str:\n",
        "    \"\"\"Retrieve relevant university snippets (profiles, groups, policies) for a query.\"\"\"\n",
        "    docs = retriever.invoke(query)\n",
        "    # Return a compact evidence string\n",
        "    return \"\\n\\n\".join([f\"[{d.metadata}] {d.page_content}\" for d in docs])\n",
        "\n",
        "tools = [university_retriever]\n",
        "tools\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[StructuredTool(name='university_retriever', description='Retrieve relevant university snippets (profiles, groups, policies) for a query.', args_schema=<class 'langchain_core.utils.pydantic.university_retriever'>, func=<function university_retriever at 0x7aa820b68cc0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "id": "_xql7G6xqEk2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRt3zgtFqEk2"
      },
      "source": [
        "## 7) Create a ReAct agent (v1) and an AgentExecutor\n",
        "LangChain v1 uses:\n",
        "- `create_react_agent` to define how the model reasons with tools\n",
        "- `AgentExecutor` to run the loop (think → tool → observe → answer)"
      ],
      "id": "PRt3zgtFqEk2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKT3RYsLqEk3",
        "outputId": "6262a608-f093-4454-9017-30618fc17258"
      },
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain.tools import tool\n",
        "from langchain.messages import HumanMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "@tool\n",
        "def university_retriever(query: str) -> str:\n",
        "    \"\"\"Retrieve relevant university snippets for a query.\"\"\"\n",
        "    docs = retriever.invoke(query)  # retriever is a Runnable in v1\n",
        "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "agent = create_agent(model, tools=[university_retriever])\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Who works on neuro-symbolic reasoning? Use the tool.\")]},\n",
        ")\n",
        "\n",
        "print(result)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [HumanMessage(content='Who works on neuro-symbolic reasoning? Use the tool.', additional_kwargs={}, response_metadata={}, id='3cec2706-15c3-4a72-b752-e9eaa45327bf'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 59, 'total_tokens': 80, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_aa07c96156', 'id': 'chatcmpl-CnI7XoXBWKf28A4GYeyzbxrDBmQax', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b25ae-a8e7-7453-b266-228c6ba9595e-0', tool_calls=[{'name': 'university_retriever', 'args': {'query': 'neuro-symbolic reasoning'}, 'id': 'call_HXikjvqEK3UVD8FAKqh1LwEw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 59, 'output_tokens': 21, 'total_tokens': 80, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Alice is a PhD student researching neuro-symbolic AI, knowledge graphs, and reasoning systems.\\n\\nBob is a Professor working on ontology engineering and graph-based AI. He supervises students.\\n\\nEnergyAIGroup focuses on AI for sustainability, energy forecasting, optimisation, and climate modelling.', name='university_retriever', id='c36dd866-f3fc-4b04-a9dc-d0c0543c58ab', tool_call_id='call_HXikjvqEK3UVD8FAKqh1LwEw'), AIMessage(content='Here are some individuals and groups working on neuro-symbolic reasoning:\\n\\n1. **Alice** - A PhD student researching neuro-symbolic AI, knowledge graphs, and reasoning systems.\\n\\n2. **Bob** - A Professor who works on ontology engineering and graph-based AI, and supervises students in this field.\\n\\n3. **EnergyAIGroup** - This group focuses on AI for sustainability, energy forecasting, optimization, and climate modeling, which may include aspects of neuro-symbolic reasoning.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 98, 'prompt_tokens': 146, 'total_tokens': 244, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_aa07c96156', 'id': 'chatcmpl-CnI7a64WBgURRci4hkTF6jta4T3a5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b25ae-b3df-78d2-a09d-99838dead33e-0', usage_metadata={'input_tokens': 146, 'output_tokens': 98, 'total_tokens': 244, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
          ]
        }
      ],
      "id": "jKT3RYsLqEk3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FgCbxQpqEk3"
      },
      "source": [
        "## 8) Run the agent"
      ],
      "id": "1FgCbxQpqEk3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLmTDLDRqEk4",
        "outputId": "85c858f5-a279-4c19-89fd-9da9a5d6a39e"
      },
      "source": [
        "agent.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Who works on neuro-symbolic reasoning? Use evidence.\")]},\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Who works on neuro-symbolic reasoning? Use evidence.', additional_kwargs={}, response_metadata={}, id='828d5a76-ecdb-4009-8f8b-108aeea17fae'),\n",
              "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 58, 'total_tokens': 79, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_aa07c96156', 'id': 'chatcmpl-CnI8m8XmKQsm4zJ5kZYpCpGH2RY5A', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b25af-d9af-7d32-9754-86a4315b5ed5-0', tool_calls=[{'name': 'university_retriever', 'args': {'query': 'neuro-symbolic reasoning'}, 'id': 'call_HPV4WRqkCW5Ow1PwuZCH02rE', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 21, 'total_tokens': 79, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='Alice is a PhD student researching neuro-symbolic AI, knowledge graphs, and reasoning systems.\\n\\nBob is a Professor working on ontology engineering and graph-based AI. He supervises students.\\n\\nEnergyAIGroup focuses on AI for sustainability, energy forecasting, optimisation, and climate modelling.', name='university_retriever', id='53790edd-48d6-444b-96bc-a704b28ece08', tool_call_id='call_HPV4WRqkCW5Ow1PwuZCH02rE'),\n",
              "  AIMessage(content='In the field of neuro-symbolic reasoning, the following individuals and groups are notable:\\n\\n1. **Alice** - A PhD student who is actively researching neuro-symbolic AI, knowledge graphs, and reasoning systems. Her work contributes to the understanding and development of neuro-symbolic approaches.\\n\\n2. **Bob** - A Professor who specializes in ontology engineering and graph-based AI. He supervises students, likely including those working on neuro-symbolic reasoning, and contributes to the academic discourse in this area.\\n\\n3. **EnergyAIGroup** - While primarily focused on AI applications for sustainability, energy forecasting, optimization, and climate modeling, their work may intersect with neuro-symbolic reasoning, especially in the context of integrating symbolic reasoning with data-driven AI for complex problem-solving.\\n\\nThese individuals and groups represent a blend of academic research and practical applications in the realm of neuro-symbolic reasoning.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 176, 'prompt_tokens': 145, 'total_tokens': 321, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_aa07c96156', 'id': 'chatcmpl-CnI8nzlzeFuvukuISeZqZk6fq4Jo6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b25af-de74-7611-802e-71562e49addd-0', usage_metadata={'input_tokens': 145, 'output_tokens': 176, 'total_tokens': 321, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "id": "fLmTDLDRqEk4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQEb77D6qEk4",
        "outputId": "2030647d-aab7-49e3-8ea3-e2cdd9fda4d5"
      },
      "source": [
        "agent.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"What database permissions are recommended for LLM tools in student labs? Use evidence.\")]},\n",
        ")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='What database permissions are recommended for LLM tools in student labs? Use evidence.', additional_kwargs={}, response_metadata={}, id='49e188a0-2919-499a-9dbf-154ce9558d7e'),\n",
              "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 63, 'total_tokens': 88, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_aa07c96156', 'id': 'chatcmpl-CnIEfwkDhXz732MpT4S6urnZRige7', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b25b5-6d3b-7030-a282-318c87438d37-0', tool_calls=[{'name': 'university_retriever', 'args': {'query': 'database permissions for LLM tools in student labs'}, 'id': 'call_0EInADMHhE3bGU5spalxt246', 'type': 'tool_call'}], usage_metadata={'input_tokens': 63, 'output_tokens': 25, 'total_tokens': 88, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='University AI policy: use least-privilege access for LLM tools, prefer read-only database permissions in labs, and validate tool outputs.\\n\\nBob is a Professor working on ontology engineering and graph-based AI. He supervises students.\\n\\nAlice is a PhD student researching neuro-symbolic AI, knowledge graphs, and reasoning systems.', name='university_retriever', id='f2b030d4-4aff-4e68-9a78-08dc36c1a232', tool_call_id='call_0EInADMHhE3bGU5spalxt246'),\n",
              "  AIMessage(content='For LLM tools in student labs, it is recommended to implement the following database permissions based on best practices:\\n\\n1. **Least-Privilege Access**: Grant only the minimum permissions necessary for users to perform their tasks. This reduces the risk of unauthorized access or data breaches.\\n\\n2. **Read-Only Permissions**: Prefer read-only database permissions for LLM tools in lab environments. This ensures that students can access and analyze data without the ability to modify or delete it, which helps maintain data integrity.\\n\\n3. **Validation of Tool Outputs**: Implement a process to validate the outputs generated by LLM tools. This is crucial to ensure that the information provided is accurate and reliable, especially when used for research or academic purposes.\\n\\nThese recommendations are supported by university policies emphasizing security and data integrity in academic settings.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 163, 'prompt_tokens': 164, 'total_tokens': 327, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_11f3029f6b', 'id': 'chatcmpl-CnIEic9a2wmlnB230IeUOjPFjR03w', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b25b5-7684-7731-8eaf-15720e6ca19f-0', usage_metadata={'input_tokens': 164, 'output_tokens': 163, 'total_tokens': 327, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "id": "bQEb77D6qEk4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP7ILFTBqEk5"
      },
      "source": [
        "## Reflection\n",
        "- What did the tool contribute?\n",
        "- What did the LLM contribute?\n",
        "- What happens if you set k=1?\n"
      ],
      "id": "eP7ILFTBqEk5"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}