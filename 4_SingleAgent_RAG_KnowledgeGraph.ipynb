{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjluY5CW7dSa"
      },
      "source": [
        "# Multiple Agents over RAG + Knowledge Graph (Neo4j)\n",
        "\n",
        "\n",
        "This notebook demonstrates a transparent multi-agent workflow:\n",
        "- Agents are built with `langchain.agents.create_agent`\n",
        "- Tools are defined with `@tool`\n",
        "- Retrievers are called with `.invoke()`\n",
        "\n",
        "### Architecture\n",
        "Planner → RAG Researcher → KG Analyst → Validator/Editor\n",
        "\n",
        "Each role is implemented as a separate **agent** with a role-specific `system_prompt`.\n"
      ],
      "id": "hjluY5CW7dSa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0Vf0AJR7dSd"
      },
      "source": [
        "## 1) Install dependencies"
      ],
      "id": "S0Vf0AJR7dSd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXEn8i0_7dSe"
      },
      "source": [
        "!pip -q install -U langchain langchain-openai langchain-neo4j neo4j langchain-community faiss-cpu tiktoken"
      ],
      "execution_count": 16,
      "outputs": [],
      "id": "JXEn8i0_7dSe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZzZew6p7dSf"
      },
      "source": [
        "## 2) Configure credentials"
      ],
      "id": "LZzZew6p7dSf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ibbrs8eG7dSg"
      },
      "source": [
        "import os, getpass\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key: \")\n",
        "\n",
        "NEO4J_URI = \"neo4j+s://ead18442.databases.neo4j.io\"\n",
        "NEO4J_USER = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"fz1Hzz1Z-Gzh8zYDwlfujRKHhTM9zq4eC5QAYp1YGWY\"\n"
      ],
      "execution_count": 17,
      "outputs": [],
      "id": "Ibbrs8eG7dSg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpjW8vpa7dSg"
      },
      "source": [
        "## 3) Build shared tools\n",
        "We create two tools that all agents can use:\n",
        "1) `rag_retrieve` — retrieves evidence from a local vector store (FAISS)\n",
        "2) `kg_query` — queries Neo4j via NL→Cypher\n",
        "\n",
        "Students should notice:\n",
        "- RAG is best for *fuzzy descriptive* questions\n",
        "- KG is best for *relationships and paths*\n"
      ],
      "id": "VpjW8vpa7dSg"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga-8T5XL7dSg"
      },
      "source": [
        "from langchain.tools import tool\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Model used by all agents\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# --- RAG corpus (small and inspectable) ---\n",
        "rag_docs = [\n",
        "    Document(page_content=\"Alice is a PhD student researching neuro-symbolic AI, knowledge graphs, and reasoning systems.\",\n",
        "             metadata={\"entity\":\"Alice\",\"type\":\"Person\"}),\n",
        "    Document(page_content=\"Bob is a Professor working on ontology engineering and graph-based AI. He supervises students.\",\n",
        "             metadata={\"entity\":\"Bob\",\"type\":\"Person\"}),\n",
        "    Document(page_content=\"EnergyAIGroup focuses on AI for sustainability, energy forecasting, optimisation, and climate modelling.\",\n",
        "             metadata={\"entity\":\"EnergyAIGroup\",\"type\":\"Group\"}),\n",
        "]\n",
        "\n",
        "# Embed + chunk + index\n",
        "emb = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "chunks = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=30).split_documents(rag_docs)\n",
        "vs = FAISS.from_documents(chunks, emb)\n",
        "\n",
        "# Retriever: v1-style call is retriever.invoke(query)\n",
        "retriever = vs.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "@tool\n",
        "def rag_retrieve(query: str) -> str:\n",
        "    \"\"\"Retrieve relevant University text snippets (RAG evidence).\"\"\"\n",
        "    hits = retriever.invoke(query)\n",
        "    return \"\\n\\n\".join([f\"[{d.metadata}] {d.page_content}\" for d in hits])\n"
      ],
      "execution_count": 18,
      "outputs": [],
      "id": "ga-8T5XL7dSg"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2WnJi2R7dSh",
        "outputId": "e218037d-ef15-4950-e25f-fed14a6ccf8e"
      },
      "source": [
        "from langchain_neo4j import Neo4jGraph, GraphCypherQAChain\n",
        "\n",
        "graph = Neo4jGraph(url=NEO4J_URI, username=NEO4J_USER, password=NEO4J_PASSWORD)\n",
        "graph.refresh_schema()\n",
        "\n",
        "kg_chain = GraphCypherQAChain.from_llm(\n",
        "    model,\n",
        "    graph=graph,\n",
        "    verbose=False,\n",
        "    validate_cypher=True,\n",
        "    allow_dangerous_requests=True,\n",
        "    use_function_response=True\n",
        ")\n",
        "\n",
        "@tool\n",
        "def kg_query(question: str) -> str:\n",
        "    \"\"\"Answer relationship/type/path questions using Neo4j (NL→Cypher).\"\"\"\n",
        "    return kg_chain.invoke({\"query\": question})[\"result\"]\n",
        "\n",
        "TOOLS = [rag_retrieve, kg_query]\n",
        "TOOLS\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[StructuredTool(name='rag_retrieve', description='Retrieve relevant University text snippets (RAG evidence).', args_schema=<class 'langchain_core.utils.pydantic.rag_retrieve'>, func=<function rag_retrieve at 0x7c68ce6d4040>),\n",
              " StructuredTool(name='kg_query', description='Answer relationship/type/path questions using Neo4j (NL→Cypher).', args_schema=<class 'langchain_core.utils.pydantic.kg_query'>, func=<function kg_query at 0x7c683418ef20>)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "id": "p2WnJi2R7dSh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nT0ul_ui7dSh"
      },
      "source": [
        "## 4) Helper: extract tool calls from the agent run (tool-selection tracing)\n",
        "LangChain v1 agents return a **state** containing a sequence of messages.\n",
        "We inspect messages to find tool calls and tool outputs so students can see *why* the agent chose RAG vs KG.\n"
      ],
      "id": "nT0ul_ui7dSh"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn03mhwn7dSh"
      },
      "source": [
        "def _msg_to_dict(m):\n",
        "    # Handle either dict messages or LangChain message objects\n",
        "    if isinstance(m, dict):\n",
        "        return m\n",
        "    d = {\"type\": type(m).__name__}\n",
        "    for attr in [\"content\", \"tool_calls\", \"name\"]:\n",
        "        if hasattr(m, attr):\n",
        "            d[attr] = getattr(m, attr)\n",
        "    return d\n",
        "\n",
        "def trace_tool_calls(state):\n",
        "    messages = state.get(\"messages\", state)  # sometimes state is a dict with messages\n",
        "    if isinstance(messages, dict) and \"messages\" in messages:\n",
        "        messages = messages[\"messages\"]\n",
        "    if not isinstance(messages, list):\n",
        "        print(\"No messages found to trace.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nTOOL TRACE (in order):\")\n",
        "    for i, m in enumerate(messages, 1):\n",
        "        md = _msg_to_dict(m)\n",
        "        tool_calls = md.get(\"tool_calls\") or md.get(\"tool_calls\", [])\n",
        "        if tool_calls:\n",
        "            print(f\"Message {i}: tool call(s) →\")\n",
        "            for tc in tool_calls:\n",
        "                # tc can be dict-like\n",
        "                name = tc.get(\"name\") if isinstance(tc, dict) else getattr(tc, \"name\", None)\n",
        "                args = tc.get(\"args\") if isinstance(tc, dict) else getattr(tc, \"args\", None)\n",
        "                print(\"  -\", name, \"args:\", args)\n",
        "\n",
        "        # Tool results often show up as ToolMessage objects with content\n",
        "        if md.get(\"type\") == \"ToolMessage\" or md.get(\"name\") in (\"rag_retrieve\", \"kg_query\"):\n",
        "            c = md.get(\"content\", \"\")\n",
        "            if c:\n",
        "                print(f\"Message {i}: tool output snippet → {str(c)[:220].replace('\\n',' ')}...\")\n",
        "\n",
        "def final_text(state):\n",
        "    messages = state.get(\"messages\", [])\n",
        "    if not messages:\n",
        "        return \"\"\n",
        "    last = messages[-1]\n",
        "    if isinstance(last, dict):\n",
        "        return last.get(\"content\", \"\")\n",
        "    return getattr(last, \"content\", str(last))\n"
      ],
      "execution_count": 27,
      "outputs": [],
      "id": "xn03mhwn7dSh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoZTcMXQ7dSi"
      },
      "source": [
        "## 5) Create role-specific agents using `create_agent`\n",
        "Each agent gets the same tools but a different system prompt.\n",
        "LangChain v1 agents are invoked with:\n",
        "`agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"...\"}]})`\n"
      ],
      "id": "FoZTcMXQ7dSi"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuWCiaVx7dSi"
      },
      "source": [
        "from langchain.agents import create_agent\n",
        "\n",
        "planner_agent = create_agent(\n",
        "    model,\n",
        "    tools=TOOLS,\n",
        "    system_prompt=(\n",
        "        \"\"\"ROLE: Planner. Break the user goal into numbered sub-questions.\n",
        "           For each sub-question, state which tool to use:\n",
        "            - Use kg_query for relationships/paths/types (supervises, member of, affiliated with, types, paths).\n",
        "            - Use rag_retrieve for fuzzy descriptions (research interests, focus areas).\n",
        "           Do NOT answer the questions. Output only the plan.\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "rag_agent = create_agent(\n",
        "    model,\n",
        "    tools=TOOLS,\n",
        "    system_prompt=(\n",
        "        \"\"\"ROLE: RAG Researcher. Use rag_retrieve to gather evidence snippets for descriptive questions.\n",
        "        Return bullet points of evidence with minimal paraphrase. Do not invent facts.\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "kg_agent = create_agent(\n",
        "    model,\n",
        "    tools=TOOLS,\n",
        "    system_prompt=(\n",
        "        \"\"\"ROLE: KG Analyst. Use kg_query for relationship/type/path questions.\n",
        "        Return concise answers. If unclear, retry the tool with a clearer question.\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "editor_agent = create_agent(\n",
        "    model,\n",
        "    tools=TOOLS,\n",
        "    system_prompt=(\n",
        "        \"\"\"ROLE: Validator/Editor. Combine evidence from the other agents into a final short report.\n",
        "        Every claim must be supported by evidence from tools. Note missing/conflicting evidence explicitly.\"\"\"\n",
        "    )\n",
        ")\n"
      ],
      "execution_count": 28,
      "outputs": [],
      "id": "iuWCiaVx7dSi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbM494wW7dSi"
      },
      "source": [
        "## 6) Orchestrate the multi-agent workflow\n",
        "We run each agent in sequence and pass the outputs forward.\n"
      ],
      "id": "KbM494wW7dSi"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE-LTRBQ7dSi",
        "outputId": "18851648-96c3-4166-b020-8fa3170e564b"
      },
      "source": [
        "user_goal = (\n",
        "    \"\"\"Write a short university profile report answering:\n",
        "    1) Who supervises Alice?\n",
        "    2) Which research group is Alice affiliated with?\n",
        "    3) What does EnergyAIGroup focus on?\n",
        "    4) Who works on neuro-symbolic reasoning?\n",
        "    Use evidence from tools.\"\"\"\n",
        ")\n",
        "\n",
        "# 1) Planner\n",
        "plan_state = planner_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_goal}]})\n",
        "print(\"\\n--- PLAN ---\\n\", final_text(plan_state))\n",
        "trace_tool_calls(plan_state)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- PLAN ---\n",
            " 1) Who supervises Alice?  \n",
            "   - Tool: kg_query\n",
            "\n",
            "2) Which research group is Alice affiliated with?  \n",
            "   - Tool: kg_query\n",
            "\n",
            "3) What does EnergyAIGroup focus on?  \n",
            "   - Tool: rag_retrieve\n",
            "\n",
            "4) Who works on neuro-symbolic reasoning?  \n",
            "   - Tool: kg_query\n",
            "\n",
            "TOOL TRACE (in order):\n"
          ]
        }
      ],
      "id": "UE-LTRBQ7dSi"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C4niPfk7dSi",
        "outputId": "761433c2-d873-4272-ce30-4b7265a232bc"
      },
      "source": [
        "# 2) RAG Researcher (descriptive questions)\n",
        "rag_request = (\n",
        "    \"\"\"Gather evidence for:\n",
        "      - What does EnergyAIGroup focus on?\n",
        "      - Who works on neuro-symbolic reasoning?\n",
        "    Use rag_retrieve and return evidence bullet points.\"\"\"\n",
        ")\n",
        "rag_state = rag_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": rag_request}]})\n",
        "print(\"\\n--- RAG EVIDENCE ---\\n\", final_text(rag_state))\n",
        "trace_tool_calls(rag_state)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- RAG EVIDENCE ---\n",
            " ### Evidence for EnergyAIGroup Focus:\n",
            "- EnergyAIGroup focuses on AI for sustainability, energy forecasting, optimisation, and climate modelling.\n",
            "\n",
            "### Evidence for Neuro-Symbolic Reasoning:\n",
            "- Alice is a PhD student researching neuro-symbolic AI, knowledge graphs, and reasoning systems.\n",
            "- Bob is a Professor working on ontology engineering and graph-based AI, and he supervises students.\n",
            "\n",
            "TOOL TRACE (in order):\n",
            "Message 2: tool call(s) →\n",
            "  - rag_retrieve args: {'query': 'What does EnergyAIGroup focus on?'}\n",
            "  - rag_retrieve args: {'query': 'Who works on neuro-symbolic reasoning?'}\n",
            "Message 3: tool output snippet → [{'entity': 'EnergyAIGroup', 'type': 'Group'}] EnergyAIGroup focuses on AI for sustainability, energy forecasting, optimisation, and climate modelling.  [{'entity': 'Alice', 'type': 'Person'}] Alice is a PhD student rese...\n",
            "Message 4: tool output snippet → [{'entity': 'Alice', 'type': 'Person'}] Alice is a PhD student researching neuro-symbolic AI, knowledge graphs, and reasoning systems.  [{'entity': 'Bob', 'type': 'Person'}] Bob is a Professor working on ontology enginee...\n"
          ]
        }
      ],
      "id": "5C4niPfk7dSi"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhQCRiN17dSi",
        "outputId": "6b9b5f95-5d3b-43c9-a234-9e28dd9065cf"
      },
      "source": [
        "# 3) KG Analyst (relationship questions)\n",
        "kg_request = (\n",
        "    \"\"\"Answer using KG evidence:\n",
        "      - Who supervises Alice?\n",
        "      - Which research group is Alice affiliated with?\n",
        "      - Which classes is Bob an instance of?\n",
        "      Use kg_query and return concise answers.\"\"\"\n",
        ")\n",
        "kg_state = kg_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": kg_request}]})\n",
        "print(\"\\n--- KG EVIDENCE ---\\n\", final_text(kg_state))\n",
        "trace_tool_calls(kg_state)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- KG EVIDENCE ---\n",
            " - Alice is supervised by no one (no information available).\n",
            "- Alice is affiliated with the EnergyAIGroup, focusing on AI applications for sustainability, energy systems, and climate modeling.\n",
            "- Bob is an instance of the classes: Academic, Professor, and Person.\n",
            "\n",
            "TOOL TRACE (in order):\n",
            "Message 2: tool call(s) →\n",
            "  - kg_query args: {'question': 'Who supervises Alice?'}\n",
            "  - kg_query args: {'question': 'Which research group is Alice affiliated with?'}\n",
            "  - kg_query args: {'question': 'Which classes is Bob an instance of?'}\n",
            "Message 3: tool output snippet → There is no information available regarding who supervises Alice....\n",
            "Message 4: tool output snippet → Alice is affiliated with the EnergyAIGroup, which focuses on AI applications for sustainability, energy systems, and climate modeling....\n",
            "Message 5: tool output snippet → Bob is an instance of the following classes: Academic, Professor, and Person....\n"
          ]
        }
      ],
      "id": "PhQCRiN17dSi"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfcBW15x7dSj",
        "outputId": "a635bd77-a982-4052-9737-f935881ff573"
      },
      "source": [
        "# 4) Validator/Editor combines everything\n",
        "final_request = (\n",
        "    \"\"\"Combine into final report.\n",
        "\n",
        "\"\n",
        "    f\"PLAN:\\n{final_text(plan_state)}\\n\\n\"\n",
        "    f\"RAG EVIDENCE:\\n{final_text(rag_state)}\\n\\n\"\n",
        "    f\"KG EVIDENCE:\\n{final_text(kg_state)}\\n\\n\"\n",
        "    \"Output format:\n",
        "    - Q1 answer + evidence\n",
        "    - Q2 answer + evidence\n",
        "    - Q3 answer + evidence\n",
        "    - Q4 answer + evidence\n",
        "    - Notes/uncertainty (if any)\n",
        "\"\"\"\n",
        ")\n",
        "final_state = editor_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": final_request}]})\n",
        "print(\"\\n--- FINAL REPORT ---\\n\", final_text(final_state))\n",
        "trace_tool_calls(final_state)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- FINAL REPORT ---\n",
            " ### Final Report\n",
            "\n",
            "**Q1 Answer:** The EnergyAIGroup is focused on AI applications for sustainability, energy forecasting, optimization, and climate modeling.  \n",
            "**Evidence:** RAG evidence indicates that \"EnergyAIGroup focuses on AI for sustainability, energy forecasting, optimisation, and climate modelling.\"\n",
            "\n",
            "---\n",
            "\n",
            "**Q2 Answer:** Bob is a Professor specializing in ontology engineering and graph-based AI, and he supervises students.  \n",
            "**Evidence:** Both RAG and KG evidence confirm that \"Bob is a Professor working on ontology engineering and graph-based AI. He supervises students.\"\n",
            "\n",
            "---\n",
            "\n",
            "**Q3 Answer:** Alice is a PhD student researching neuro-symbolic AI, knowledge graphs, and reasoning systems.  \n",
            "**Evidence:** RAG and KG evidence state that \"Alice is a PhD student researching neuro-symbolic AI, knowledge graphs, and reasoning systems.\"\n",
            "\n",
            "---\n",
            "\n",
            "**Q4 Answer:** The knowledge graph reflects the current state of individuals involved, specifically Alice and Bob, with their respective roles and research focuses.  \n",
            "**Evidence:** The KG evidence details the profiles of Alice and Bob, confirming their roles and research areas.\n",
            "\n",
            "---\n",
            "\n",
            "**Notes/Uncertainty:** No conflicting evidence was found; all claims are consistently supported by the retrieved data.\n",
            "\n",
            "TOOL TRACE (in order):\n",
            "Message 2: tool call(s) →\n",
            "  - rag_retrieve args: {'query': 'final_text(plan_state)'}\n",
            "  - rag_retrieve args: {'query': 'final_text(rag_state)'}\n",
            "  - kg_query args: {'question': 'final_text(kg_state)'}\n",
            "Message 3: tool output snippet → [{'entity': 'EnergyAIGroup', 'type': 'Group'}] EnergyAIGroup focuses on AI for sustainability, energy forecasting, optimisation, and climate modelling.  [{'entity': 'Bob', 'type': 'Person'}] Bob is a Professor working on...\n",
            "Message 4: tool output snippet → [{'entity': 'EnergyAIGroup', 'type': 'Group'}] EnergyAIGroup focuses on AI for sustainability, energy forecasting, optimisation, and climate modelling.  [{'entity': 'Bob', 'type': 'Person'}] Bob is a Professor working on...\n",
            "Message 5: tool output snippet → The final text for the knowledge graph state includes the following individuals:  1. **Alice**:     - Profile: PhD student researching neuro-symbolic AI, knowledge graphs, and reasoning systems.    - ID: Alice    - Title...\n"
          ]
        }
      ],
      "id": "qfcBW15x7dSj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL0puXaC7dSj"
      },
      "source": [
        "## 7) Reflection\n",
        "1) Which tool was used where (RAG vs KG), and why?\n",
        "2) What could still fail (missing KG data, weak retrieval, tool misuse)?\n",
        "3) What extra validation would you add in production (e.g., rerun kg_query, add read-only DB user, add a judge agent)?\n"
      ],
      "id": "lL0puXaC7dSj"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}